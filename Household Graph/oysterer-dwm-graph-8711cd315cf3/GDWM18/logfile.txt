Data Washing Machine Refactor Version 1.8
Data/Time 20221028_15_19

>> Starting DWM20
Input Reference File Name = data/S1G.txt
Tokenized Reference Output File Name = logs/data/S1G-Tokenized.txt
Input File has Header Records = True
Input File Delimiter = ,
Tokenizer Function Type = Splitter
Remove Duplicate Reference Tokens = False
Total References Read= 50
Total Tokens Found = 626
Total Unique Tokens = 252
Minimum Token Frequency = 1
Maximum Token Frequency = 47
  Token= NC Frequency= 47
  Token= AARON Frequency= 33
  Token= WINSTON Frequency= 31
  Token= SALEM Frequency= 31
  Token= RD Frequency= 13
Average Token Frequency = 5.921725239616613
Standard Deviation of Token Frequency = 9.024032922506851

>>Starting DWM30
Total References Read from  Tokenized.txt = 0

>>Starting Iterations
mu start value= 0.01
mu iterate value= 0.05
epsilon start value= 0.5
epsilon iterate value= 0.0
comparator = ScoringMatrixStd

****New Iteration
Size of refList = 0 Size of linkIndex = 0

>>Starting DWM40
Beta = 6
Min blocking token length = 0
Exclude numeric blocking tokens = False
Remove excluded blocking tokens = False
Sigma = 7
Stop Words excluded= 0
Total Blocking Records Created 0
--Ending because blockList is empty
Record written to logs/data/S1G-LinkIndex.txt = 0

>>Starting DWM97

Cluster Profile
Size	Count
	Total	 0

Cluster Profile
Size	Count
	Total	 0
